\def\year{2015}
%File: formatting-instruction.tex
\documentclass[letterpaper]{article}

% Required Packages
\usepackage{aaai}
\usepackage{times}
\usepackage{helvet}
\usepackage{courier}
\usepackage{graphicx}
\frenchspacing
\setlength{\pdfpagewidth}{8.5in}
\setlength{\pdfpageheight}{11in}

\graphicspath{{./image/}}

% Section numbers. 
\setcounter{secnumdepth}{2}  

\nocopyright
\begin{document}
% Title and author information
\title{Assignment 3 report - Group: YSoSirius \\ 02285 AI \& MAS}
\author{Bogdan Sorlea \\ s121075 \And Rasmus Kr{\o}yer J{\o}rgensen \\ s090487}
\maketitle
\begin{abstract}
The abstract goes here. Please read this document carefully before preparing your manuscript.

To ensure that all reports have a uniform appearance corresponding to published papers at the major AI conferences (like IJCAI and AAAI), authors must adhere to the following instructions. 
\end{abstract}

\section{Introduction}
Introduction goes here.

\section{Background}
Stuff about the theories that our program is based on.

\section{Related work}
Research needs to be done. This section could be moved.

\section{Method}
This section contains a detailed explanation of the algorithm our client uses. Each step will be explained in its own section. There will less focus on the theory behind this solution as this should be clear from the previous section.

\begin{figure}[!htb]
\centering
\includegraphics[width=\linewidth]{ClientFlowchart.pdf}
\caption{Flowchart of the base client loop}
\label{fig:clientFlowchart}
\end{figure}

Figure \ref{clientFlowchart} shows a visual reprensentation of the main client loop.

\subsection{Preprocessing}
The first step upon start-up is the pre-processing step. This step is not part of the core loop of the client and will only be executed once. In this part we first read the input to the server to create our perception of the map. After this we perform a simple form of goal decomposition. Each goal cell is treated as a independent goal that must be achieved. Then for each goal we calculate the goal priority. The priority is based on whether or not other goal cells block this goal cell - that is if by solving the other goals you will then block access to this goal. Once each goal cell has a priority we then calculate the exact distance from each cell to each goal cell. This will help us have a more efficient heuristic when we want to know the distance from the boxes to the goal cells.

\subsubsection{Distance map}

While incrementally developing the solution, we took the decision to simplify as much as possible, wherever it was possible. One such simplifications relied on pre-computing a distance map for each of the goal cells. The rationale behind it was that if we could obtain a solution that is not computationally intensive for computing the minimum distances from each cell to each goal cell, as the goal cells stay constant (a goal cannot be moved), then we would have a very precise metric to include in our heuristic function, which would ultimately make the solution more robust.

For computing this distance map we took an approach based on starting from the goal cell and, using the 4-vicinity, continuously add neighbors into a frontier list, that would be continuously processed until empty. The processing consists of always storing the minimum distance to a specific cell, which is based on the distance to its parent, incremented by one.

The usage of the frontier data structure and of the way the distance is computed can be considered to be structurally similar to how the best-first strategy algorithm work - which itself is an important part of the solution, in exploring the state space.

Specific measures were taken in order to increase the performance of the algorithm, most important one being a check based on which the iteration would just continue if a specific cell has been already processed (i.e. due to a different - and therefore possibly shorter - path from the goal to that specific cell).

The result of applying the aforementioned algorithm is a map of distances similar to the one in Figure \ref{fig:distmapb}, which corresponds for the level in Figure \ref{fig:distmaporig} and the goal denoted by \textit{b}.

\begin{figure}[!htb]
\centering
\begin{minipage}[b]{0.45\linewidth}
	\centering
	\includegraphics[scale=0.4]{distmap_orig.JPG}
	\caption{Original level}
	\label{fig:distmaporig}
\end{minipage}
\quad
\begin{minipage}[b]{0.45\linewidth}
	\centering
	\includegraphics[scale=0.5]{distmap_b.JPG}
	\caption{Distances to \textit{b}}
	\label{fig:distmapb}
\end{minipage}
\end{figure}

It is noteworthy that the algorithm itself does not take into account situations where a level is split into two or more disjoint areas, where one area is not reachable from another and this might lead to exceptions in some levels. Therefore, this scenario can be improved by map initialization to an arbitrary flag that indicates that the cell has not been reached in any way from the goal.

\subsection{Find solution}
In relation to the BDI architecture this step involves updating the Beliefs, Desires and Intention of each agent. In this step each agent will first update their desire, which in our context is to find a new sub-goal (found from the goal decomposition mentioned above). If the agent does already have a goal and this is not yet achieved then no new goal is given. If the agent is not done and is not quarantined (explained later) then it is given an updated version of the map and the positions of agents and boxes. From this state the agent uses a graph search tree with a heuristic function to find a state that satisfies its goal. During this search process the agent assumes that the map stays unchanged, except for the changes made by the agent. The agent also cannot see obstacles in the form of boxes of another color or other agents, so it will plan as if they are not there (but these can still influence the heuristic function).

\subsubsection{Heuristic function}
The heuristic function we use is a relaxed, admissible heuristic function. It uses the A* as its basis which means that it will add a $g()$ function to all heuristics. The $g()$ functions return the number of steps to the initial state of the search tree. The $h()$ part of the heuristic function is found in the following way. It will find the box closest to the goal cell that the agent is trying to solve and then find the distance between the two, using the goal distance map we calculated during the pre-processing. It will then find the Manhattan distance between the agent and the box chosen and add that to the earlier distance found and this will be the foundation of the returned value. There are few other things that influence the heuristic:
\begin{itemize}
\item Moving a box that is not the box found earlier will add to the returned value
\item Moving a box or the agent into a cell the is occupied by another box or agent will add to the returned value.
\item Moving a box or the agent into a cell that is a solved goal cell will add greatly to the returned value.
\end{itemize}
Since the search function will chose the state whose heuristic function returns the lowest value, adding to the value returned effectively discourages the agent from choosing that state. \textit{Possibly explain why heuristic is admissible and relaxed}.

\subsection{Execute plan}
Once each agent has a plan that will solve its current subgoal, the plan will be executed. The loop that executes the plan will terminate if the server responds \textit{false} to any of the actions given - that is if the action an agent is trying to do is not possible. The client has a blackboard architecture and has a shared variable that holds the current state of the map. This variable is updated each time and agent has performed an action successfully. It is the same variable that an agent copies when it updates its beliefs in the previous stage. Once all agents have executed their plan the loop terminates, assuming it was not terminated prematurely because of a conflict.

\subsection{Conflict resolution}
When the loop mentioned above a check is made for each agent to find out if its last action results in an error. If there was no error then all plans were executed successfully and this step is skipped. However, if an agent ended the loop with an error, then this agent will request the cells that it is going to occupy in the next action of its plan to be cleared. It will send this request to all other agents, and if either the agent itself occupies one of cells to be cleared, or if the agent has the same color as a box that occupies a cell to be cleared, then this agent will search for a plan to clear these cells.

Because the next action will always only occupy one new cell, it will also always only need one agent to help do the clear. In an earlier iteration of the system the agent would request all cells that will at one time get occupied in its plan to be cleared, and the fact that it sends the clearing request to all agents is a remnant of this system. This is discussed furter in the discussion section. 


\section{Results}
Discuss our results.

\section{Discussion}
Why did we do what we did? What was good and bad etc.

\section{Future work}
For future work we consider some of the ideas we had during the implementation, but for various reasons we decided not to include them. We will be describing the ideas, the benefits and well as the disadvantages and other notable details.

\subsection{Reducing the state space}
One idea we considered at an early stage in the project was to try and reduce the state-space of each level, thus reducing the complexity of searching in this state-space. The abstract description on how to achieve this is by removing some of the cells in the level, for example by marking them (in a separate data structure than the one storing the original level) as being walls, such that the overall function of the level is not perturbed (i.e. all paths from agents to boxes and from boxes to goals are still valid after running the algorithm that reduces the state-space).

Applying such an algorithm will result in a level with more wall cells, therefore less cells that can be occupied by an object (box, agent or goal), resulting in a decreased complexity while searching, by reducing the base of the exponential function that defines this complexity (by the number of converted cells), therefore reducing the search's branching factor.

While this improves performance while searching, it has the disadvantage of making conflict resolution more cumbersome, unless special procedures are considered in this case. One such procedure can be conflict solving in the original state-space (in the original layout of the level), while all other search taking place in the reduced state-space. Another consequence of such an implementation is an increased probability of conflicts, as the chances of bottlenecks being formed are higher.

This idea can be implemented based on an algorithm in Image Processing and Computer Vision called "dilation", a morphological step used in various algorithms, e.g. removing noise from an image. The details of this algorithm can be consulted in [make proper reference: http://users.utcluj.ro/~igiosan/Resources/PI/L7/PI-L7e.pdf], but in our case it translates to a simple routine: it would mark a non-wall cell as wall cell if at least one of the cell's neighbors in its 4-vicinity is a wall cell. The union of this set of newly marked wall cells and the walls in the original level (or walls in the previous iteration, if applied iteratively) will form the final walls in the level.

This is an efficient implementation, not computationally complex, but however, it has some disadvantages we are still thinking how to best overcome. The disadvantages are given by the complex nature of the reasoning that will assure that at each dilation iteration we are not isolating any of the cells of interest, i.e. boxes, goals or agents. While we have thought about this problem and we have some ideas on how to overcome it, we would first have to experiment with some strategies before we would be able to strongly claim any solution. Therefore, we are just raising awareness on the issue but not offering a concrete solution at this time.

On a related topic, another challenge to iterative dilation is reasoning about when to stop dilating the walls of the level. This is also something to experiment with and therefore no solution would be provided here.

An example of this level transformation works can be seen in Figure \ref{fig:level_before_dilation} and Figure \ref{fig:level_after_dilation}, where in Figure \ref{fig:level_before_dilation} we see the original walls of the level and in Figure \ref{fig:level_after_dilation} we see the final walls after the dilation (run for 1 iteration, based on the 4-vicinity kernel). Note that in Figure \ref{fig:level_after_dilation} we have ignored the walls that would be computed outside the bounds of the original level, as are they deemed irrelevant.

\begin{figure}[!htb]
\centering
\begin{minipage}[b]{0.45\linewidth}
	\centering
	\includegraphics[scale=0.4]{level_before_dilation.JPG}
	\caption{Walls before dilation}
	\label{fig:level_before_dilation}
\end{minipage}
\quad
\begin{minipage}[b]{0.45\linewidth}
	\centering
	\includegraphics[scale=0.5]{level_after_dilation.JPG}
	\caption{Wall after dilation (1 iteration)}
	\label{fig:level_after_dilation}
\end{minipage}
\end{figure}

We have decided not to proceed with experimenting and implementing this solution at an early stage in the project. There are two main reasons behind this decision: we saw this as possibly complicated in terms of the algorithm, provided that all functional safety measures are to be taken in regards to the level and we found other ideas as more efficient (e.g. computing a distance map for each of the goals) and therefore considered that such a solution might not bring a huge benefit. However, it is an interesting idea that is worth an investigation, as the complexity of the resulting algorithm would most likely be fairly small, \textit{O(m*n)}, where \textit{m} and \textit{n} are the dimensions of the original level.


\section{Bibliography}
Your bibliography should be formatted using \texttt{aaai.bst} as this document. Citations are included like so~\cite{book2015}. Multiple citations appear like this~\cite{conf,article}. All references to be cited should be included in BibTeX format in the file \texttt{bibliography.bib}.\footnote{Almost anything ever published can be found in BibTeX format via Google Scholar, but if using this method, you need to check the BibTeX entry for sanity before including it in the \texttt{bibliography.bib} file.}



% References and end of paper
\bibliographystyle{aaai}
\bibliography{bibliography}


\end{document}
